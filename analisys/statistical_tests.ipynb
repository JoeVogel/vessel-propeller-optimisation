{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_run = '../results'\n",
    "\n",
    "NSEEDS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_result_df(best_result_file_path):\n",
    "    history = []\n",
    "    with open(best_result_file_path, 'r', newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        counter = 0\n",
    "        for row in reader:\n",
    "            if counter == 1:\n",
    "                params = row\n",
    "            elif counter == 3:\n",
    "                history = row\n",
    "            elif counter == 5:\n",
    "                configs = row\n",
    "            counter += 1\n",
    "    # D, AEdAO, PdD, Z, fitness\n",
    "    D       = float(params[0])\n",
    "    AEdAO   = float(params[1])\n",
    "    PdD     = float(params[2])\n",
    "    Z       = int(params[3]) if len(params[3]) == 1 else int(float(params[3]))\n",
    "    fitness = float(params[6])\n",
    "    # history    \n",
    "    if len(history) > 0:\n",
    "        history = [float(h) for h in history]\n",
    "    # configs\n",
    "    solver_name = configs[0]\n",
    "    vs        = float(configs[1])\n",
    "    seed        = int(configs[4])\n",
    "    # create new entry in df\n",
    "    new_data = {'D': D, \n",
    "                'AEdAO': AEdAO, \n",
    "                'PdD': PdD,\n",
    "                'Z': int(Z),\n",
    "                'Brake Power': -fitness,\n",
    "                'Seed': seed,\n",
    "                'Algorithm': solver_name,\n",
    "                'VS': vs}\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best by seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'D': [], 'AEdAO': [], 'PdD': [], 'Z': [], 'Brake Power': [], 'Seed': [], 'Algorithm': [], 'VS': []}\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "for algorithm in listdir(dir_run):\n",
    "    algorithm_folder = dir_run + '/' + algorithm\n",
    "\n",
    "    for speed in listdir(algorithm_folder):  # Loop sobre as velocidades\n",
    "        speed_folder = algorithm_folder + '/' + speed\n",
    "        \n",
    "        for seed in range(NSEEDS):\n",
    "            seed_folder = speed_folder + '/' + str(seed)\n",
    "                \n",
    "            best_result_file = [filename for filename in listdir(seed_folder) if 'best_results' in filename]\n",
    "            \n",
    "            if len(best_result_file) > 0:\n",
    "                best_result_file = best_result_file[0]\n",
    "                best_result_file = seed_folder+'/'+best_result_file\n",
    "                new_data = get_best_result_df(best_result_file)\n",
    "                df_results = pd.concat([df_results, pd.DataFrame(new_data, index=[0])], ignore_index=True)\n",
    " \n",
    "df_results = df_results.astype({\"Z\": int, \"Seed\": int})   \n",
    "df_results = df_results.drop('Seed', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cmaes = df_results.loc[df_results['Algorithm'] == 'cmaes']\n",
    "df_openaies = df_results.loc[df_results['Algorithm'] == 'openaies']\n",
    "df_de = df_results.loc[df_results['Algorithm'] == 'DE']\n",
    "df_de_mod = df_results.loc[df_results['Algorithm'] == 'DE_mod']\n",
    "\n",
    "df_cmaes = df_cmaes.drop('Algorithm', axis=1)\n",
    "df_openaies = df_openaies.drop('Algorithm', axis=1)\n",
    "df_de = df_de.drop('Algorithm', axis=1)\n",
    "df_de_mod = df_de_mod.drop('Algorithm', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate replicaed DE dataset\n",
    "# Replicated DE has only 2 because it only run for 7 and 7.5 of V_S\n",
    "\n",
    "df_de_7   = df_de.loc[df_de['VS'] == 7.0]\n",
    "df_de_7_5 = df_de.loc[df_de['VS'] == 7.5]\n",
    "\n",
    "df_de_7   = df_de_7.drop('VS', axis=1)\n",
    "df_de_7_5 = df_de_7_5.drop('VS', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate modified DE dataset\n",
    "\n",
    "df_de_mod_7   = df_de_mod.loc[df_de_mod['VS'] == 7.0]\n",
    "df_de_mod_7_5 = df_de_mod.loc[df_de_mod['VS'] == 7.5]\n",
    "df_de_mod_8   = df_de_mod.loc[df_de_mod['VS'] == 8.0]\n",
    "df_de_mod_8_5 = df_de_mod.loc[df_de_mod['VS'] == 8.5]\n",
    "\n",
    "df_de_mod_7   = df_de_mod_7.drop('VS', axis=1)\n",
    "df_de_mod_7_5 = df_de_mod_7_5.drop('VS', axis=1)\n",
    "df_de_mod_8   = df_de_mod_8.drop('VS', axis=1)\n",
    "df_de_mod_8_5 = df_de_mod_8_5.drop('VS', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cmaes dataset\n",
    "\n",
    "df_cmaes_7      = df_cmaes.loc[df_cmaes['VS'] == 7.0]\n",
    "df_cmaes_7_5    = df_cmaes.loc[df_cmaes['VS'] == 7.5]\n",
    "df_cmaes_8      = df_cmaes.loc[df_cmaes['VS'] == 8.0]\n",
    "df_cmaes_8_5    = df_cmaes.loc[df_cmaes['VS'] == 8.5]\n",
    "\n",
    "df_cmaes_7      = df_cmaes_7.drop('VS', axis=1)\n",
    "df_cmaes_7_5    = df_cmaes_7_5.drop('VS', axis=1)\n",
    "df_cmaes_8      = df_cmaes_8.drop('VS', axis=1)\n",
    "df_cmaes_8_5    = df_cmaes_8_5.drop('VS', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate openaies dataset\n",
    "\n",
    "df_openaies_7   = df_openaies.loc[df_openaies['VS'] == 7.0]\n",
    "df_openaies_7_5 = df_openaies.loc[df_openaies['VS'] == 7.5]\n",
    "df_openaies_8   = df_openaies.loc[df_openaies['VS'] == 8.0]\n",
    "df_openaies_8_5 = df_openaies.loc[df_openaies['VS'] == 8.5]\n",
    "\n",
    "df_openaies_7   = df_openaies_7.drop('VS', axis=1)\n",
    "df_openaies_7_5 = df_openaies_7_5.drop('VS', axis=1)\n",
    "df_openaies_8   = df_openaies_8.drop('VS', axis=1)\n",
    "df_openaies_8_5 = df_openaies_8_5.drop('VS', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>AEdAO</th>\n",
       "      <th>PdD</th>\n",
       "      <th>Z</th>\n",
       "      <th>Brake Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.661627</td>\n",
       "      <td>0.669448</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.551321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.018635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.625847</td>\n",
       "      <td>0.640228</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.432608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.647030</td>\n",
       "      <td>0.658366</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.477026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.657047</td>\n",
       "      <td>0.664718</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.528028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.668007</td>\n",
       "      <td>0.678906</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.575100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.730914</td>\n",
       "      <td>0.701546</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.865217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          D      AEdAO        PdD     Z  Brake Power\n",
       "count  10.0  10.000000  10.000000  10.0    10.000000\n",
       "mean    0.8   0.661627   0.669448   5.0    81.551321\n",
       "std     0.0   0.028011   0.018635   0.0     0.125404\n",
       "min     0.8   0.625847   0.640228   5.0    81.432608\n",
       "25%     0.8   0.647030   0.658366   5.0    81.477026\n",
       "50%     0.8   0.657047   0.664718   5.0    81.528028\n",
       "75%     0.8   0.668007   0.678906   5.0    81.575100\n",
       "max     0.8   0.730914   0.701546   5.0    81.865217"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_de_7.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapiro-Wilk Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapiro_wilk(df):\n",
    "    try:\n",
    "        stat, p_value = shapiro(df['Brake Power'])\n",
    "        return {'Estatística de Shapiro-Wilk': stat, 'Valor p': p_value}\n",
    "    except Exception as e:\n",
    "        print('Erro ' + str(e))\n",
    "        return {'Erro': str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests\n",
    "\n",
    "Hypothesis H0 (Null Hypothesis): Brake Power obtained by Algorithm 1 does not have statistical difference compared to that obtained by Algorithm 2.\n",
    "\n",
    "We will try to prove this with 95% confidence.\n",
    "\n",
    "In the hypothesis test (which is either the t-test or Mann-Whitney depending on the distribution format), it will return a value. If the value is less than 5% (p=0.05), they are different; otherwise, there is no way to prove the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_statistical_test(df_a, df_b):\n",
    "    significance_level = 0.05\n",
    "    \n",
    "    df_a_result = shapiro_wilk(df_a)\n",
    "    df_b_result = shapiro_wilk(df_b)\n",
    "    \n",
    "    # If p-values less than 0.05 (Significance Level) use Mann-Whitney U, otherwise, use T-Test\n",
    "    if df_a_result['Valor p'] > significance_level and df_b_result['Valor p'] > significance_level:\n",
    "        # Use T-Test\n",
    "        t_statistic, p_value = ttest_ind(df_a['Brake Power'], df_b['Brake Power'])\n",
    "        return {'Algorithm':'t-test', 'Statistic':statistic, 'p-value':p_value}\n",
    "    else:\n",
    "        # Use Mann-Whitney U\n",
    "        statistic, p_value = mannwhitneyu(df_a['Brake Power'], df_b['Brake Power'], alternative='two-sided')\n",
    "        return {'Algorithm':'mann-whitney-u', 'Statistic':statistic, 'p-value':p_value}\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinations of tests\n",
    "\n",
    "For V_S [7 and 7.5], we need to compare the four algorithms:\n",
    "\n",
    "DE      - DE_MOD \\\n",
    "DE      - CMA-ES \\\n",
    "DE      - OpenAI-ES \\\n",
    "DE_MOD  - CMA-ES \\\n",
    "DE_MOD  - OpenAI-ES \\\n",
    "CMA-ES  - OpenAI-ES \n",
    "\n",
    "For V_S [8 and 8.5], replicated DE didn't run. Because of that we need to run less tests:\n",
    "\n",
    "DE_MOD  - CMA-ES \\\n",
    "DE_MOD  - OpenAI-ES \\\n",
    "CMA-ES  - OpenAI-ES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V_S = 7\n",
    "de_de_mod_7     = run_statistical_test(df_de_7, df_de_mod_7)\n",
    "de_cma_7        = run_statistical_test(df_de_7, df_cmaes_7)\n",
    "de_openai_7     = run_statistical_test(df_de_7, df_openaies_7)\n",
    "de_mod_cma_7    = run_statistical_test(df_de_mod_7, df_cmaes_7)\n",
    "de_mod_openai_7 = run_statistical_test(df_de_mod_7, df_openaies_7)\n",
    "cma_openai_7    = run_statistical_test(df_cmaes_7, df_openaies_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 78.0, 'p-value': 0.03763531378731424}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 82.0, 'p-value': 0.017257456083119765}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 30.0, 'p-value': 0.14046504815835495}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 57.0, 'p-value': 0.6231762238821174}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 15.0, 'p-value': 0.009108496398030963}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 12.0, 'p-value': 0.004586392080253494}\n"
     ]
    }
   ],
   "source": [
    "print(de_de_mod_7)\n",
    "print(de_cma_7)\n",
    "print(de_openai_7)\n",
    "print(de_mod_cma_7)\n",
    "print(de_mod_openai_7)\n",
    "print(cma_openai_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V_S = 7_5\n",
    "de_de_mod_7_5       = run_statistical_test(df_de_7_5, df_de_mod_7_5)\n",
    "de_cma_7_5          = run_statistical_test(df_de_7_5, df_cmaes_7_5)\n",
    "de_openai_7_5       = run_statistical_test(df_de_7_5, df_openaies_7_5)\n",
    "de_mod_cma_7_5      = run_statistical_test(df_de_mod_7_5, df_cmaes_7_5)\n",
    "de_mod_openai_7_5   = run_statistical_test(df_de_mod_7_5, df_openaies_7_5)\n",
    "cma_openai_7_5      = run_statistical_test(df_cmaes_7_5, df_openaies_7_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 84.0, 'p-value': 0.011329696684474668}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 85.0, 'p-value': 0.009108496398030963}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 28.0, 'p-value': 0.10410988966022681}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 48.0, 'p-value': 0.9097218891455553}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 1.0, 'p-value': 0.00024612812790522973}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 0.0, 'p-value': 0.00018267179110955002}\n"
     ]
    }
   ],
   "source": [
    "print(de_de_mod_7_5)\n",
    "print(de_cma_7_5)\n",
    "print(de_openai_7_5)\n",
    "print(de_mod_cma_7_5)\n",
    "print(de_mod_openai_7_5)\n",
    "print(cma_openai_7_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V_S = 8\n",
    "de_mod_cma_8      = run_statistical_test(df_de_mod_8, df_cmaes_8)\n",
    "de_mod_openai_8   = run_statistical_test(df_de_mod_8, df_openaies_8)\n",
    "cma_openai_8      = run_statistical_test(df_cmaes_8, df_openaies_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 72.0, 'p-value': 0.10410988966022681}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 25.0, 'p-value': 0.06402210128302689}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 2.0, 'p-value': 0.00032983852077799353}\n"
     ]
    }
   ],
   "source": [
    "print(de_mod_cma_8)\n",
    "print(de_mod_openai_8)\n",
    "print(cma_openai_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V_S = 8.5\n",
    "de_mod_cma_8_5      = run_statistical_test(df_de_mod_8_5, df_cmaes_8_5)\n",
    "de_mod_openai_8_5   = run_statistical_test(df_de_mod_8_5, df_openaies_8_5)\n",
    "cma_openai_8_5      = run_statistical_test(df_cmaes_8_5, df_openaies_8_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 78.0, 'p-value': 0.03763531378731424}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 32.0, 'p-value': 0.18587673236587576}\n",
      "{'Algorithm': 'mann-whitney-u', 'Statistic': 14.0, 'p-value': 0.0072845570094796615}\n"
     ]
    }
   ],
   "source": [
    "print(de_mod_cma_8_5)\n",
    "print(de_mod_openai_8_5)\n",
    "print(cma_openai_8_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonferroni correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonferroni_correction(mw_results, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Applies Bonferroni correction to the results of the Mann-Whitney U test.\n",
    "\n",
    "    Args:\n",
    "    - mw_results (list): List containing dictionaries with the results of the Mann-Whitney U test.\n",
    "                         Each dictionary should have keys 'Algorithm', 'Statistic', and 'p-value'.\n",
    "    - alpha (float): Significance level.\n",
    "\n",
    "    Returns:\n",
    "    - corrected_results (list): List containing the corrected results after Bonferroni correction.\n",
    "                                Each element of the list is a boolean indicating whether the null hypothesis was rejected\n",
    "                                (True for rejected, False otherwise).\n",
    "    \"\"\"\n",
    "    # Extracting p-values from mw_results\n",
    "    p_values = [result['p-value'] for result in mw_results]\n",
    "    \n",
    "    # Applying Bonferroni correction\n",
    "    corrected_p_values = multipletests(p_values, alpha=alpha, method='bonferroni')[1]\n",
    "    \n",
    "    # Converting corrected p-values into boolean results\n",
    "    # corrected_results = [p_value < alpha for p_value in corrected_p_values]\n",
    "    \n",
    "    return corrected_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results corrected after Bonferroni:\n",
      "[0.22581188 0.10354474 0.84279029 1.         0.05465098 0.02751835]\n"
     ]
    }
   ],
   "source": [
    "# V_S = 7\n",
    "\n",
    "results = [de_de_mod_7, de_cma_7, de_openai_7, de_mod_cma_7, de_mod_openai_7, cma_openai_7]\n",
    "\n",
    "corrected_results = bonferroni_correction(results)\n",
    "\n",
    "print(\"Results corrected after Bonferroni:\")\n",
    "print(corrected_results)\n",
    "\n",
    "de_de_mod_7_corrected     = corrected_results[0]\n",
    "de_cma_7_corrected        = corrected_results[1]\n",
    "de_openai_7_corrected     = corrected_results[2]\n",
    "de_mod_cma_7_corrected    = corrected_results[3]\n",
    "de_mod_openai_7_corrected = corrected_results[4]\n",
    "cma_openai_7_corrected    = corrected_results[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results corrected after Bonferroni:\n",
      "[0.06797818 0.05465098 0.62465934 1.         0.00147677 0.00109603]\n"
     ]
    }
   ],
   "source": [
    "# V_S = 7.5\n",
    "\n",
    "results = [de_de_mod_7_5, de_cma_7_5, de_openai_7_5, de_mod_cma_7_5, de_mod_openai_7_5, cma_openai_7_5]\n",
    "\n",
    "corrected_results = bonferroni_correction(results)\n",
    "\n",
    "print(\"Results corrected after Bonferroni:\")\n",
    "print(corrected_results)\n",
    "\n",
    "de_de_mod_7_5_corrected     = corrected_results[0]\n",
    "de_cma_7_5_corrected        = corrected_results[1]\n",
    "de_openai_7_5_corrected     = corrected_results[2]\n",
    "de_mod_cma_7_5_corrected    = corrected_results[3]\n",
    "de_mod_openai_7_5_corrected = corrected_results[4]\n",
    "cma_openai_7_5_corrected    = corrected_results[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results corrected after Bonferroni:\n",
      "[0.31232967 0.1920663  0.00098952]\n"
     ]
    }
   ],
   "source": [
    "# V_S = 8\n",
    "\n",
    "results = [de_mod_cma_8, de_mod_openai_8, cma_openai_8]\n",
    "\n",
    "corrected_results = bonferroni_correction(results)\n",
    "\n",
    "print(\"Results corrected after Bonferroni:\")\n",
    "print(corrected_results)\n",
    "\n",
    "de_mod_cma_8_corrected     = corrected_results[0]\n",
    "de_mod_openai_8_corrected  = corrected_results[1]\n",
    "cma_openai_8_corrected     = corrected_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results corrected after Bonferroni:\n",
      "[0.11290594 0.5576302  0.02185367]\n"
     ]
    }
   ],
   "source": [
    "# V_S = 8.5\n",
    "\n",
    "results = [de_mod_cma_8_5, de_mod_openai_8_5, cma_openai_8_5]\n",
    "\n",
    "corrected_results = bonferroni_correction(results)\n",
    "\n",
    "print(\"Results corrected after Bonferroni:\")\n",
    "print(corrected_results)\n",
    "\n",
    "de_mod_cma_8_5_corrected     = corrected_results[0]\n",
    "de_mod_openai_8_5_corrected  = corrected_results[1]\n",
    "cma_openai_8_5_corrected     = corrected_results[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
